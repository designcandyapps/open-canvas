# LangSmith tracing
# Set this to `false` to disable tracing to LangSmith
LANGCHAIN_TRACING_V2=true
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="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"
LANGSMITH_PROJECT="dcdb"
LANGCHAIN_PROJECT="dcdb"

# LLM API keys
ANTHROPIC_API_KEY=
OPENAI_API_KEY=openai_api_key
GOOGLE_API_KEY=
FIREWORKS_API_KEY=

# Feature flags for hiding/showing specific models
NEXT_PUBLIC_FIREWORKS_ENABLED=true
NEXT_PUBLIC_GEMINI_ENABLED=true
NEXT_PUBLIC_ANTHROPIC_ENABLED=true
NEXT_PUBLIC_OPENAI_ENABLED=true
# Set to false by default since the base OpenAI API is more common than the Azure OpenAI API.
NEXT_PUBLIC_AZURE_ENABLED=false
NEXT_PUBLIC_OLLAMA_ENABLED=false

# If using Ollama, set the API URL here. Only needs to be set if using the non default Ollama server port.
# It will default to `http://host.docker.internal:11434` if not set.
# OLLAMA_API_URL="http://host.docker.internal:11434"

# LangGraph Deployment, or local development server via LangGraph Studio.
# If running locally, this URL should be set in the `constants.ts` file.
# LANGGRAPH_API_URL=

# Supabase for authentication
NEXT_PUBLIC_SUPABASE_URL=https://vhpzzaloepwnwgoxhoga.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZocHp6YWxvZXB3bndnb3hob2dhIiwicm9sZSI6ImFub24iLCJpYXQiOjE3Mzc1NjU5MzgsImV4cCI6MjA1MzE0MTkzOH0.VqOW0osJXsuGVn1A9BiA1N5k2yt41VNjQ4NloFGBE3A

# Azure OpenAI Configuration
# ENSURE THEY ARE PREFIXED WITH AN UNDERSCORE.
_AZURE_OPENAI_API_KEY=your-azure-openai-api-key
_AZURE_OPENAI_API_INSTANCE_NAME=your-instance-name
_AZURE_OPENAI_API_DEPLOYMENT_NAME=your-deployment-name
_AZURE_OPENAI_API_VERSION=2024-08-01-preview
# Optional: Azure OpenAI Base Path (if using a different domain)
# _AZURE_OPENAI_API_BASE_PATH=https://your-custom-domain.com/openai/deployments
